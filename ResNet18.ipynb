{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4cb810-867b-4bbb-9875-eb41a67d3552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before loading model:  2024-10-16 17:09:59.357482\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import datetime\n",
    "from torchvision import transforms\n",
    "from torchvision.models import squeezenet1_1\n",
    "from PIL import Image\n",
    "import time\n",
    "# from jtop import jtop\n",
    "# jetson = jtop()\n",
    "# jetson.start()\n",
    "# print(\"Before loading model: \",jetson.stats)\n",
    "\n",
    "print(\"Before loading model: \",datetime.datetime.now())\n",
    "# Load the pre-trained ResNet model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "# print(model)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Load and preprocess an example image\n",
    "image_path = '1.jpg'\n",
    "input_image = Image.open(image_path).convert('RGB')\n",
    "# print(\"Image transformation: \",jetson.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9671f4-fe24-4363-912e-e18dcf383c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image transformation:  2024-10-16 17:11:01.991894\n"
     ]
    }
   ],
   "source": [
    "print(\"Image transformation: \",datetime.datetime.now())\n",
    "# Define the image transformation pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to the input image\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e25fabc-3eae-4e50-965c-3cdc4b881ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During prediction:  2024-10-16 17:11:04.863260\n",
      "tensor([264])\n",
      "Predicted class: Dogs\n",
      "Inference time: 0.3979 seconds\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    print(\"During prediction: \", datetime.datetime.now())\n",
    "    # print(\"During prediction: \",jtop().stats)\n",
    "    output = model(input_batch)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Get the predicted class index\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "print(predicted_idx)\n",
    "predicted_class = \"Cats\" if predicted_idx.item() == 0 else \"Dogs\"\n",
    "\n",
    "# Print the predicted class label and inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c7ae83-5200-43b6-91c6-c69d6cfa36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ed354-2eae-493b-ad9a-17a12ad9e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained Mobilenetv3 model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Define input size (224x224x3) for Mobilenetv3\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.MaxPool2d):\n",
    "            # For max pooling layers\n",
    "            output_size = (input_size[0] - module.kernel_size) // module.stride + 1\n",
    "            flops += input_size[2] * output_size * output_size\n",
    "            input_size = (output_size, output_size, input_size[2])\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf935cd-344f-49a6-843e-ef6ade442aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
