{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66d14db-9304-4f69-9b9a-cacbcddb6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47ecb55-7fef-4c89-933f-bd8fb86fc704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): ConvNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v3_small(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f5ef81-eb31-4de7-903d-c6c780a98221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before loading model:  2024-10-18 17:57:17.025792+01:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "from PIL import Image\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "def read_classes():\n",
    "    \"\"\"\n",
    "    Load the ImageNet class names.\n",
    "    \"\"\"\n",
    "    with open(\"imagenet-classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip() for s in f.readlines()]\n",
    "    return categories\n",
    "\n",
    "print(\"Before loading model: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "# Load the pre-trained Mobilenetv3 model\n",
    "model = mobilenet_v3_small(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "categories = read_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c45434-dfd1-4cca-a05a-1ef703607305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image:  2024-10-18 18:08:15.296827+01:00\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess an example image\n",
    "print(\"Loading image: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "image_path = 'dog_1.jpg'\n",
    "input_image = Image.open(image_path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6ff3e25-4806-4a53-add7-2f31e7d603ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image transformation:  2024-10-18 18:08:18.284938+01:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Image transformation: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "# Define the image transformation pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to the input image\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d400eb17-0bc5-4953-af58-907f96fb0d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During prediction:  2024-10-18 18:08:22.015930+01:00\n",
      "Inference time: 2.6493 seconds\n",
      "Accuracy: 81.686%\n",
      "Predicted class:Newfoundland, Newfoundland dog\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    print(\"During prediction: \", datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "    # print(\"During prediction: \",jtop().stats)\n",
    "    output = model(input_batch)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Get the predicted class index\n",
    "# get the softmax probabilities\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "# check the top category that are predicted\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 1)\n",
    "\n",
    "# Print the predicted class label and inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n",
    "print(f\"Accuracy: {top5_prob[0].item()*100:.3f}%\")\n",
    "print(f\"Predicted class:{categories[top5_catid[0]]}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84a0703-b565-4e1a-95e3-539af4ba25ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 2542856\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e911f2d-d0d9-42cb-a896-b03a03af9956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 29234304\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained Mobilenetv3 model\n",
    "model = mobilenet_v3_small(pretrained=True)\n",
    "\n",
    "# Define input size (224x224x3) for Mobilenetv3\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.MaxPool2d):\n",
    "            # For max pooling layers\n",
    "            output_size = (input_size[0] - module.kernel_size) // module.stride + 1\n",
    "            flops += input_size[2] * output_size * output_size\n",
    "            input_size = (output_size, output_size, input_size[2])\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc58d1-61e4-4ac7-8394-9e17eb45200d",
   "metadata": {},
   "source": [
    "Total FLOPs: 29234304\n",
    "Before loading model:  2024-10-18 17:57:17.025792+01:00\n",
    "\n",
    "0: 1.jpg\n",
    "\n",
    "Loading image:  2024-10-18 17:57:31.158511+01:00\n",
    "Image transformation:  2024-10-18 17:57:35.574077+01:00\n",
    "During prediction:  2024-10-18 17:57:39.639212+01:00\n",
    "Inference time: 2.9779 seconds\n",
    "Accuracy: 40.332%\n",
    "Predicted class:Italian greyhound\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 17, 948191)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 18, 950298)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 19, 952551)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 20, 942129)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 21, 943182)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 22, 943864)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 23, 957899)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 24, 966308)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 25, 954725)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 26, 951080)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 27, 965039)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 28, 964528)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 29, 970994)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 30, 957246)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 31, 966759)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 32, 969495)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 33, 959996)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 34, 972118)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 35, 974874)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 36, 975562)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 37, 976466)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 38, 966991)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 40, 053279)\n",
    "\n",
    "Average CPU Temperature: 31.13°C\n",
    "Average GPU Temperature: 32.02°C\n",
    "Average Power CPU: 868.96mW\n",
    "Average Power GPU: 868.96mW\n",
    "Average Power TOT: 2325.17mW\n",
    "Average RAM: 0.4688\n",
    "\n",
    "{'Avg_CPU_temp': 31.130434782608695, 'Avg_GPU_temp': 32.02173913043478, 'Avg_Power_CPU': 868.9565217391304, 'Avg_Power_GPU': 868.9565217391304, 'Avg_CPU_RAM': 0.46881048197927816}\n",
    "\n",
    "1: cat_0\n",
    "\n",
    "Loading image:  2024-10-18 17:59:21.789642+01:00\n",
    "Image transformation:  2024-10-18 17:59:24.607439+01:00\n",
    "During prediction:  2024-10-18 17:59:27.012594+01:00\n",
    "Inference time: 2.8112 seconds\n",
    "Accuracy: 14.485%\n",
    "Predicted class:water jug\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 21, 120204)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 22, 126424)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 23, 124276)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 24, 117592)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 25, 121873)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 26, 135385)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 27, 196186)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 28, 133128)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 29, 181014)\n",
    "\n",
    "Average CPU Temperature: 31.61°C\n",
    "Average GPU Temperature: 32.50°C\n",
    "Average Power CPU: 1231.00mW\n",
    "Average Power GPU: 1231.00mW\n",
    "Average Power TOT: 2643.22mW\n",
    "Average RAM: 0.4709\n",
    "{'Avg_CPU_temp': 31.61111111111111, 'Avg_GPU_temp': 32.5, 'Avg_Power_CPU': 1231.0, 'Avg_Power_GPU': 1231.0, 'Avg_CPU_RAM': 0.4708981101005223}\n",
    "\n",
    "2: cat_1\n",
    "Loading image:  2024-10-18 18:01:04.291168+01:00\n",
    "Image transformation:  2024-10-18 18:01:06.273660+01:00\n",
    "During prediction:  2024-10-18 18:01:09.836196+01:00\n",
    "Inference time: 2.8233 seconds\n",
    "Accuracy: 53.589%\n",
    "Predicted class:tabby, tabby cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 04, 259825)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 05, 279781)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 06, 262401)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 07, 274778)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 08, 276707)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 09, 277619)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 10, 316841)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 11, 342538)\n",
    "\n",
    "Average CPU Temperature: 31.69°C\n",
    "Average GPU Temperature: 32.69°C\n",
    "Average Power CPU: 1076.88mW\n",
    "Average Power GPU: 1076.88mW\n",
    "Average Power TOT: 2453.38mW\n",
    "Average RAM: 0.4712\n",
    "{'Avg_CPU_temp': 31.6875, 'Avg_GPU_temp': 32.6875, 'Avg_Power_CPU': 1076.875, 'Avg_Power_GPU': 1076.875, 'Avg_CPU_RAM': 0.47117206669228723}\n",
    "\n",
    "3: dog_0\n",
    "\n",
    "Loading image:  2024-10-18 18:03:41.256764+01:00\n",
    "Image transformation:  2024-10-18 18:03:43.954394+01:00\n",
    "During prediction:  2024-10-18 18:03:50.639748+01:00\n",
    "Inference time: 2.9095 seconds\n",
    "Accuracy: 69.595%\n",
    "Predicted class:malamute, malemute, Alaskan malamute\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 41, 482930)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 42, 480816)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 43, 488559)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 44, 482902)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 45, 488933)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 46, 492824)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 47, 505770)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 48, 501570)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 49, 491754)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 50, 501876)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 51, 510798)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 52, 532689)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 53, 498738)\n",
    "\n",
    "Average CPU Temperature: 31.58°C\n",
    "Average GPU Temperature: 32.50°C\n",
    "Average Power CPU: 1027.62mW\n",
    "Average Power GPU: 1027.62mW\n",
    "Average Power TOT: 2414.23mW\n",
    "Average RAM: 0.4707\n",
    "{'Avg_CPU_temp': 31.576923076923077, 'Avg_GPU_temp': 32.5, 'Avg_Power_CPU': 1027.6153846153845, 'Avg_Power_GPU': 1027.6153846153845, 'Avg_CPU_RAM': 0.4706899283154936}\n",
    "\n",
    "4: cat_2\n",
    "\n",
    "Loading image:  2024-10-18 18:05:06.948375+01:00\n",
    "Image transformation:  2024-10-18 18:05:09.383007+01:00\n",
    "During prediction:  2024-10-18 18:05:12.125914+01:00\n",
    "Inference time: 2.8526 seconds\n",
    "Accuracy: 99.132%\n",
    "Predicted class:Persian cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 06, 602950)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 07, 604978)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 08, 603793)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 09, 602987)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 10, 610692)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 11, 607423)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 12, 657260)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 13, 695027)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 14, 633435)\n",
    "\n",
    "Average CPU Temperature: 32.06°C\n",
    "Average GPU Temperature: 32.72°C\n",
    "Average Power CPU: 1279.44mW\n",
    "Average Power GPU: 1279.44mW\n",
    "Average Power TOT: 2683.11mW\n",
    "Average RAM: 0.4706\n",
    "{'Avg_CPU_temp': 32.05555555555556, 'Avg_GPU_temp': 32.72222222222222, 'Avg_Power_CPU': 1279.4444444444443, 'Avg_Power_GPU': 1279.4444444444443, 'Avg_CPU_RAM': 0.4706216489348307}\n",
    "\n",
    "5: dog_1\n",
    "\n",
    "Loading image:  2024-10-18 18:08:15.296827+01:00\n",
    "Image transformation:  2024-10-18 18:08:18.284938+01:00\n",
    "During prediction:  2024-10-18 18:08:22.015930+01:00\n",
    "Inference time: 2.6493 seconds\n",
    "Accuracy: 81.686%\n",
    "Predicted class:Newfoundland, Newfoundland dog\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 15, 866883)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 16, 864828)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 17, 858168)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 18, 875126)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 19, 869052)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 20, 874626)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 21, 874836)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 22, 882504)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 23, 974059)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 24, 877386)\n",
    "\n",
    "Average CPU Temperature: 31.80°C\n",
    "Average GPU Temperature: 32.60°C\n",
    "Average Power CPU: 1156.60mW\n",
    "Average Power GPU: 1156.60mW\n",
    "Average Power TOT: 2546.70mW\n",
    "Average RAM: 0.4706\n",
    "\n",
    "{'Avg_CPU_temp': 31.8, 'Avg_GPU_temp': 32.6, 'Avg_Power_CPU': 1156.6, 'Avg_Power_GPU': 1156.6, 'Avg_CPU_RAM': 0.4705887801657453}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
