{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc2263c-3ad7-4b20-8089-cd0a2701a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained SqueezeNet model\n",
    "model = models.squeezenet1_1(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59269b12-8d10-473c-8e29-5951685fcad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (6): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c409b9bc-4aab-4191-be8f-93d2ddc4fe0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before loading model:  2024-10-18 17:15:58.497908+01:00\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import squeezenet1_1\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "def read_classes():\n",
    "    \"\"\"\n",
    "    Load the ImageNet class names.\n",
    "    \"\"\"\n",
    "    with open(\"imagenet-classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip() for s in f.readlines()]\n",
    "    return categories\n",
    "\n",
    "print(\"Before loading model: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "# Load the pre-trained SqueezeNet model\n",
    "model = squeezenet1_1(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "categories = read_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55f9155a-b950-4445-a9a7-65f8055d688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image:  2024-10-18 17:30:47.709394+01:00\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess an example image\n",
    "print(\"Loading image: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "image_path = 'dog_1.jpg'\n",
    "input_image = Image.open(image_path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2be83e97-db89-482b-a80e-129f7e9e92c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image transformation:  2024-10-18 17:30:49.373018+01:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Image transformation: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "# Define the image transformation pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to the input image\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25bb6a3f-057a-4bc0-83c1-46fa340161ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During prediction:  2024-10-18 17:30:51.788812+01:00\n",
      "Inference time: 0.2037 seconds\n",
      "Accuracy: 28.500%\n",
      "Predicted class:Newfoundland, Newfoundland dog\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    print(\"During prediction: \", datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "    # print(\"During prediction: \",jtop().stats)\n",
    "    output = model(input_batch)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Get the predicted class index\n",
    "# get the softmax probabilities\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "# check the top category that are predicted\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 1)\n",
    "\n",
    "# Print the predicted class label and inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n",
    "print(f\"Accuracy: {top5_prob[0].item()*100:.3f}%\")\n",
    "print(f\"Predicted class:{categories[top5_catid[0]]}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a58f75-4577-41cd-bf4e-2322907c54f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1235496\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d3ea22e-75cf-4dc6-8f87-b26ce859bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 78414144\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained SqueezeNet model\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "\n",
    "# Define input size (224x224x3) for SqueezeNet\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.MaxPool2d):\n",
    "            # For max pooling layers\n",
    "            output_size = (input_size[0] - module.kernel_size) // module.stride + 1\n",
    "            flops += input_size[2] * output_size * output_size\n",
    "            input_size = (output_size, output_size, input_size[2])\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26037083-6866-434a-8a21-27764cf6bc55",
   "metadata": {},
   "source": [
    "Total FLOPs: 78414144\n",
    "Before loading model:  2024-10-18 17:15:58.497908+01:00\n",
    "\n",
    "0: 1.jpg\n",
    "\n",
    "Loading image:  2024-10-18 17:16:03.225230+01:00\n",
    "Image transformation:  2024-10-18 17:16:06.776816+01:00\n",
    "During prediction:  2024-10-18 17:16:47.169217+01:00\n",
    "Inference time: 0.2406 seconds\n",
    "Accuracy: 36.797%\n",
    "Predicted class:Italian greyhound\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 15, 58, 473191)\n",
    "datetime.datetime(2024, 10, 18, 17, 15, 59, 474734)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 00, 471542)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 01, 487971)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 02, 483455)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 03, 477773)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 04, 488956)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 05, 491392)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 06, 496376)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 07, 488938)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 08, 495191)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 09, 487683)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 10, 492668)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 11, 531887)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 12, 498758)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 13, 503234)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 14, 505264)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 15, 508592)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 16, 495212)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 17, 510283)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 18, 515166)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 19, 510467)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 20, 514992)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 21, 518498)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 22, 504932)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 23, 515739)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 24, 513081)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 25, 508490)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 26, 520334)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 27, 522590)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 28, 527114)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 29, 521484)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 30, 514442)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 31, 523594)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 32, 526074)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 33, 519163)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 34, 529945)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 35, 520158)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 36, 532454)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 37, 532545)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 38, 535359)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 39, 538522)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 40, 536767)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 41, 544925)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 42, 539870)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 43, 545569)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 44, 539006)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 45, 535824)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 46, 546790)\n",
    "datetime.datetime(2024, 10, 18, 17, 16, 47, 540044)\n",
    "\n",
    "Average CPU Temperature: 30.56°C\n",
    "Average GPU Temperature: 31.67°C\n",
    "Average Power CPU: 607.02mW\n",
    "Average Power GPU: 607.02mW\n",
    "Average Power TOT: 2003.18mW\n",
    "Average RAM: 0.4492\n",
    "\n",
    "{'Avg_CPU_temp': 30.56, 'Avg_GPU_temp': 31.67, 'Avg_Power_CPU': 607.02, 'Avg_Power_GPU': 607.02, 'Avg_CPU_RAM': 0.4491608675515615}\n",
    "\n",
    "1: cat_0\n",
    "\n",
    "Loading image:  2024-10-18 17:20:34.085449+01:00\n",
    "Image transformation:  2024-10-18 17:20:37.033955+01:00\n",
    "During prediction:  2024-10-18 17:20:40.340777+01:00\n",
    "Inference time: 0.1844 seconds\n",
    "Accuracy: 21.240%\n",
    "Predicted class:tabby, tabby cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 20, 34, 852576)\n",
    "datetime.datetime(2024, 10, 18, 17, 20, 35, 863440)\n",
    "datetime.datetime(2024, 10, 18, 17, 20, 36, 865007)\n",
    "datetime.datetime(2024, 10, 18, 17, 20, 37, 865598)\n",
    "datetime.datetime(2024, 10, 18, 17, 20, 38, 870484)\n",
    "datetime.datetime(2024, 10, 18, 17, 20, 39, 873867)\n",
    "datetime.datetime(2024, 10, 18, 17, 20, 40, 851437)\n",
    "\n",
    "Average CPU Temperature: 30.93°C\n",
    "Average GPU Temperature: 31.57°C\n",
    "Average Power CPU: 646.43mW\n",
    "Average Power GPU: 646.43mW\n",
    "Average Power TOT: 1989.29mW\n",
    "Average RAM: 0.4511\n",
    "\n",
    "{'Avg_CPU_temp': 30.928571428571427, 'Avg_GPU_temp': 31.571428571428573, 'Avg_Power_CPU': 646.4285714285714, 'Avg_Power_GPU': 646.4285714285714, 'Avg_CPU_RAM': 0.4510510764154304}\n",
    "\n",
    "2: cat_1\n",
    "\n",
    "Loading image:  2024-10-18 17:23:27.504687+01:00\n",
    "Image transformation:  2024-10-18 17:23:29.394820+01:00\n",
    "During prediction:  2024-10-18 17:23:32.067847+01:00\n",
    "Inference time: 0.2234 seconds\n",
    "Accuracy: 50.415%\n",
    "Predicted class:tabby, tabby cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 23, 27, 098893)\n",
    "datetime.datetime(2024, 10, 18, 17, 23, 28, 099090)\n",
    "datetime.datetime(2024, 10, 18, 17, 23, 29, 103469)\n",
    "datetime.datetime(2024, 10, 18, 17, 23, 30, 100937)\n",
    "datetime.datetime(2024, 10, 18, 17, 23, 31, 101939)\n",
    "datetime.datetime(2024, 10, 18, 17, 23, 32, 130194)\n",
    "\n",
    "Average CPU Temperature: 30.50°C\n",
    "Average GPU Temperature: 31.83°C\n",
    "Average Power CPU: 652.33mW\n",
    "Average Power GPU: 652.33mW\n",
    "Average Power TOT: 2067.67mW\n",
    "Average RAM: 0.4508\n",
    "\n",
    "{'Avg_CPU_temp': 30.5, 'Avg_GPU_temp': 31.833333333333332, 'Avg_Power_CPU': 652.3333333333334, 'Avg_Power_GPU': 652.3333333333334, 'Avg_CPU_RAM': 0.4508495843228453}\n",
    "\n",
    "3: dog_0\n",
    "\n",
    "Loading image:  2024-10-18 17:25:17.763404+01:00\n",
    "Image transformation:  2024-10-18 17:25:19.575718+01:00\n",
    "During prediction:  2024-10-18 17:25:21.917458+01:00\n",
    "Inference time: 0.1840 seconds\n",
    "Accuracy: 60.378%\n",
    "Predicted class:malamute, malemute, Alaskan malamute\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 25, 17, 269413)\n",
    "datetime.datetime(2024, 10, 18, 17, 25, 18, 266322)\n",
    "datetime.datetime(2024, 10, 18, 17, 25, 19, 255503)\n",
    "datetime.datetime(2024, 10, 18, 17, 25, 20, 263574)\n",
    "datetime.datetime(2024, 10, 18, 17, 25, 21, 260694)\n",
    "datetime.datetime(2024, 10, 18, 17, 25, 22, 256494)\n",
    "\n",
    "Average CPU Temperature: 30.92°C\n",
    "Average GPU Temperature: 31.83°C\n",
    "Average Power CPU: 838.50mW\n",
    "Average Power GPU: 838.50mW\n",
    "Average Power TOT: 2199.50mW\n",
    "Average RAM: 0.4509\n",
    "\n",
    "{'Avg_CPU_temp': 30.916666666666668, 'Avg_GPU_temp': 31.833333333333332, 'Avg_Power_CPU': 838.5, 'Avg_Power_GPU': 838.5, 'Avg_CPU_RAM': 0.450908380222242}\n",
    "\n",
    "4: cat_2\n",
    "\n",
    "Loading image:  2024-10-18 17:26:44.837699+01:00\n",
    "Image transformation:  2024-10-18 17:26:47.417476+01:00\n",
    "During prediction:  2024-10-18 17:26:50.994242+01:00\n",
    "Inference time: 0.1520 seconds\n",
    "Accuracy: 99.602%\n",
    "Predicted class:Persian cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 26, 44, 383309)\n",
    "datetime.datetime(2024, 10, 18, 17, 26, 45, 383375)\n",
    "datetime.datetime(2024, 10, 18, 17, 26, 46, 377124)\n",
    "datetime.datetime(2024, 10, 18, 17, 26, 47, 383045)\n",
    "datetime.datetime(2024, 10, 18, 17, 26, 48, 385981)\n",
    "datetime.datetime(2024, 10, 18, 17, 26, 49, 387068)\n",
    "datetime.datetime(2024, 10, 18, 17, 26, 50, 389945)\n",
    "datetime.datetime(2024, 10, 18, 17, 26, 51, 386007)\n",
    "\n",
    "Average CPU Temperature: 30.88°C\n",
    "Average GPU Temperature: 31.88°C\n",
    "Average Power CPU: 746.88mW\n",
    "Average Power GPU: 746.88mW\n",
    "Average Power TOT: 2114.88mW\n",
    "Average RAM: 0.4510\n",
    "\n",
    "{'Avg_CPU_temp': 30.875, 'Avg_GPU_temp': 31.875, 'Avg_Power_CPU': 746.875, 'Avg_Power_GPU': 746.875, 'Avg_CPU_RAM': 0.4510115193977198}\n",
    "\n",
    "5: dog_1\n",
    "\n",
    "Loading image:  2024-10-18 17:30:47.709394+01:00\n",
    "Image transformation:  2024-10-18 17:30:49.373018+01:00\n",
    "During prediction:  2024-10-18 17:30:51.788812+01:00\n",
    "Inference time: 0.2037 seconds\n",
    "Accuracy: 28.500%\n",
    "Predicted class:Newfoundland, Newfoundland dog\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 30, 47, 731809)\n",
    "datetime.datetime(2024, 10, 18, 17, 30, 48, 725311)\n",
    "datetime.datetime(2024, 10, 18, 17, 30, 49, 720824)\n",
    "datetime.datetime(2024, 10, 18, 17, 30, 50, 726526)\n",
    "datetime.datetime(2024, 10, 18, 17, 30, 51, 719657)\n",
    "datetime.datetime(2024, 10, 18, 17, 30, 52, 727802)\n",
    "\n",
    "Average CPU Temperature: 30.58°C\n",
    "Average GPU Temperature: 31.75°C\n",
    "Average Power CPU: 503.67mW\n",
    "Average Power GPU: 503.67mW\n",
    "Average Power TOT: 1887.17mW\n",
    "Average RAM: 0.4509\n",
    "\n",
    "{'Avg_CPU_temp': 30.583333333333332, 'Avg_GPU_temp': 31.75, 'Avg_Power_CPU': 503.6666666666667, 'Avg_Power_GPU': 503.6666666666667, 'Avg_CPU_RAM': 0.4508814457878814}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
