{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f5ef81-eb31-4de7-903d-c6c780a98221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from enum import Enum\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"cpu_logs_exe_mobilenet_max.txt\", filemode=\"a+\",format=\"\")\n",
    "\n",
    "def read_classes():\n",
    "    \"\"\"\n",
    "    Load the ImageNet class names.\n",
    "    \"\"\"\n",
    "    with open(\"imagenet-classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip() for s in f.readlines()]\n",
    "    return categories\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "logging.info(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75db1dd8-045e-4221-b5b3-e9ccd6382da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6c225-ec85-4ab3-88f8-5c6756512b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before loading model:  2024-11-01 19:34:13.200190+00:00\n",
      "After loading model:  2024-11-01 19:34:13.712775+00:00\n",
      "Loaded PyTorch mobilenetv3 pretrained on ImageNet\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "    \n",
    "def load_model(model_name):\n",
    "    if model_name == \"resnet50\":\n",
    "        model = models.resnet50(weights= models.ResNet50_Weights.IMAGENET1K_V1)    \n",
    "    elif model_name == \"mobilenetv3\":\n",
    "        model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
    "    elif model_name == \"resnet18\":\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    elif model_name == \"resnext50\":\n",
    "        model = models.resnext50_32x4d(weights=models.ResNeXt50_32X4D_Weights.IMAGENET1K_V1)\n",
    "    elif model_name == \"squeezenet\":\n",
    "        model = models.squeezenet1_1(weights=models.SqueezeNet1_1_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        print(f\"Model {model_name} not supported yet.\")\n",
    "        sys.exit(1)\n",
    "    print(\"After loading model: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "    logging.info(f\"After loading model: {datetime.datetime.now(pytz.timezone('Europe/London'))}\")\n",
    "    print(f\"Loaded PyTorch {model_name} pretrained on ImageNet\")\n",
    "    logging.info(f\"Loaded PyTorch {model_name} pretrained on ImageNet\")\n",
    "    return model\n",
    "    \n",
    "print(\"Before loading model: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "logging.info(f\"Before loading model: {datetime.datetime.now(pytz.timezone('Europe/London'))}\")\n",
    "# Load the pre-trained Mobilenetv3 model\n",
    "model = load_model(\"mobilenetv3\")\n",
    "model = model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "categories = read_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db393e2f-2812-42ef-832a-48bea21b8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image_path, target_size):\n",
    "    print(\"Loading image: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "    logging.info(f\"Loading image: {datetime.datetime.now(pytz.timezone('Europe/London'))}\")\n",
    "    input_image = Image.open(image_path).convert('RGB')\n",
    "    if input_image is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    logging.info(f\"Image transformation: {datetime.datetime.now(pytz.timezone('Europe/London'))}\")\n",
    "    # Define the image transformation pipeline\n",
    "    width, height = input_image.size  # Height x Width\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Apply transformations to the input image\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    return input_batch, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400eb17-0bc5-4953-af58-907f96fb0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction\n",
    "\n",
    "def classify_images(model, fps):\n",
    "    target_size = (224, 224)\n",
    "    # interval = 1 / fps\n",
    "    images_dir = \"./Images\"\n",
    "    loop_run_count = 0\n",
    "    for loop_run_count in range(1,101):\n",
    "        print(f\"Loop run count: {loop_run_count}\")\n",
    "        logging.info(f\"Loop run count: {loop_run_count}\")\n",
    "        for image_file in sorted(os.listdir(images_dir)):\n",
    "            image_path = os.path.join(images_dir, image_file)\n",
    "            \n",
    "            if not image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "            start_time = time.time()\n",
    "            img, width, height = preprocess_image(image_path, target_size)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                img = img.to(device)\n",
    "                print(\"During prediction: \", datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "                logging.info(f\"During prediction: {datetime.datetime.now(pytz.timezone('Europe/London'))}\")\n",
    "                predictions = model(img)\n",
    "                end_time = time.time()\n",
    "                predicted_class = predictions.argmax(dim=1).item() \n",
    "\n",
    "            # Get the predicted class index\n",
    "            # get the softmax probabilities\n",
    "            probabilities = torch.nn.functional.softmax(predictions[0], dim=0)\n",
    "            # check the top category that are predicted\n",
    "            top5_prob, top5_catid = torch.topk(probabilities, 1)\n",
    "\n",
    "            print(f\"Image: {image_file}\")\n",
    "            logging.info(f\"Image: {image_file}\") \n",
    "            logging.info(f\"Resolution: {height}x{width}\")\n",
    "            # logging.info(f\"Set FPS: {fps}\")\n",
    "            # Print the predicted class label and inference time\n",
    "            inference_time = end_time - start_time\n",
    "            # latency  is total inference time divided with actual runs without the initial model inference time\n",
    "            if device == \"cuda\":\n",
    "                latency = inference_time / 8 # divided with 8 as initial 2 runs out of 10 has higher inference time for model loading\n",
    "            else: \n",
    "                latency = inference_time / 10\n",
    "            \n",
    "            # print(f'Inference time: {inference_time:.4f} seconds')\n",
    "            # print(f\"Accuracy: {top5_prob[0].item()*100:.3f}%\")\n",
    "            # print(f\"Argmax Pred class:{categories[predicted_class]}\")\n",
    "            # print(f\"TopK Predicted class:{categories[top5_catid[0]]}\")\n",
    "            # print(f'Latency: {latency:.4f} seconds')\n",
    "            print(\"\")\n",
    "\n",
    "            logging.info(f'Inference time: {inference_time:.4f} seconds')\n",
    "            logging.info(f\"Accuracy: {top5_prob[0].item()*100:.3f}%\")\n",
    "            logging.info(f\"Argmax Pred class:{categories[predicted_class]}\")\n",
    "            logging.info(f\"TopK Predicted class:{categories[top5_catid[0]]}\")\n",
    "            logging.info(f'Latency: {latency:.4f} seconds')\n",
    "            logging.info(\"\")\n",
    "            # if inference_time < interval:\n",
    "            #     time.sleep(interval - inference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d054266-cf14-4286-a466-9e8035b27651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop run count: 1\n",
      "Loading image:  2024-11-01 19:34:36.027812+00:00\n",
      "During prediction:  2024-11-01 19:34:36.342373+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:34:39.232733+00:00\n",
      "During prediction:  2024-11-01 19:34:39.267367+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:34:41.988009+00:00\n",
      "During prediction:  2024-11-01 19:34:42.009388+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:34:44.887617+00:00\n",
      "During prediction:  2024-11-01 19:34:44.924685+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:34:47.823971+00:00\n",
      "During prediction:  2024-11-01 19:34:47.859652+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:34:50.538359+00:00\n",
      "During prediction:  2024-11-01 19:34:50.574891+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 2\n",
      "Loading image:  2024-11-01 19:34:53.362184+00:00\n",
      "During prediction:  2024-11-01 19:34:53.395851+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:34:56.101131+00:00\n",
      "During prediction:  2024-11-01 19:34:56.143404+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:34:58.987730+00:00\n",
      "During prediction:  2024-11-01 19:34:59.010280+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:01.810840+00:00\n",
      "During prediction:  2024-11-01 19:35:01.841394+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:04.631066+00:00\n",
      "During prediction:  2024-11-01 19:35:04.660469+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:07.362105+00:00\n",
      "During prediction:  2024-11-01 19:35:07.387256+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 3\n",
      "Loading image:  2024-11-01 19:35:10.273007+00:00\n",
      "During prediction:  2024-11-01 19:35:10.299788+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:13.123393+00:00\n",
      "During prediction:  2024-11-01 19:35:13.159504+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:15.948158+00:00\n",
      "During prediction:  2024-11-01 19:35:15.981196+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:18.842383+00:00\n",
      "During prediction:  2024-11-01 19:35:18.868324+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:21.533136+00:00\n",
      "During prediction:  2024-11-01 19:35:21.569186+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:24.498656+00:00\n",
      "During prediction:  2024-11-01 19:35:24.530804+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 4\n",
      "Loading image:  2024-11-01 19:35:27.394708+00:00\n",
      "During prediction:  2024-11-01 19:35:27.428364+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:30.295787+00:00\n",
      "During prediction:  2024-11-01 19:35:30.338157+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:33.194627+00:00\n",
      "During prediction:  2024-11-01 19:35:33.227440+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:36.074634+00:00\n",
      "During prediction:  2024-11-01 19:35:36.111702+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:38.918031+00:00\n",
      "During prediction:  2024-11-01 19:35:38.947602+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:41.818341+00:00\n",
      "During prediction:  2024-11-01 19:35:41.846422+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 5\n",
      "Loading image:  2024-11-01 19:35:44.682146+00:00\n",
      "During prediction:  2024-11-01 19:35:44.706934+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:47.299863+00:00\n",
      "During prediction:  2024-11-01 19:35:47.332694+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:50.188592+00:00\n",
      "During prediction:  2024-11-01 19:35:50.214990+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:53.119936+00:00\n",
      "During prediction:  2024-11-01 19:35:53.150874+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:56.024795+00:00\n",
      "During prediction:  2024-11-01 19:35:56.060886+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:35:58.880802+00:00\n",
      "During prediction:  2024-11-01 19:35:58.916583+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 6\n",
      "Loading image:  2024-11-01 19:36:01.862466+00:00\n",
      "During prediction:  2024-11-01 19:36:01.895497+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:04.827385+00:00\n",
      "During prediction:  2024-11-01 19:36:04.868850+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:07.686567+00:00\n",
      "During prediction:  2024-11-01 19:36:07.719447+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:10.637771+00:00\n",
      "During prediction:  2024-11-01 19:36:10.675711+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:13.351278+00:00\n",
      "During prediction:  2024-11-01 19:36:13.375693+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:16.238252+00:00\n",
      "During prediction:  2024-11-01 19:36:16.274417+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 7\n",
      "Loading image:  2024-11-01 19:36:19.004003+00:00\n",
      "During prediction:  2024-11-01 19:36:19.036973+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:21.885808+00:00\n",
      "During prediction:  2024-11-01 19:36:21.919762+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:24.594092+00:00\n",
      "During prediction:  2024-11-01 19:36:24.630062+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:27.267656+00:00\n",
      "During prediction:  2024-11-01 19:36:27.293084+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:30.212636+00:00\n",
      "During prediction:  2024-11-01 19:36:30.239161+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:33.002900+00:00\n",
      "During prediction:  2024-11-01 19:36:33.039136+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 8\n",
      "Loading image:  2024-11-01 19:36:35.750009+00:00\n",
      "During prediction:  2024-11-01 19:36:35.782930+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:38.454055+00:00\n",
      "During prediction:  2024-11-01 19:36:38.485390+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:41.416897+00:00\n",
      "During prediction:  2024-11-01 19:36:41.449650+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:44.092296+00:00\n",
      "During prediction:  2024-11-01 19:36:44.129017+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:46.897042+00:00\n",
      "During prediction:  2024-11-01 19:36:46.932853+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:49.651556+00:00\n",
      "During prediction:  2024-11-01 19:36:49.675321+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 9\n",
      "Loading image:  2024-11-01 19:36:52.460174+00:00\n",
      "During prediction:  2024-11-01 19:36:52.487366+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:55.361319+00:00\n",
      "During prediction:  2024-11-01 19:36:55.396799+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:36:58.244514+00:00\n",
      "During prediction:  2024-11-01 19:36:58.277222+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:01.183762+00:00\n",
      "During prediction:  2024-11-01 19:37:01.221441+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:04.094675+00:00\n",
      "During prediction:  2024-11-01 19:37:04.124111+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:06.940334+00:00\n",
      "During prediction:  2024-11-01 19:37:06.976451+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 10\n",
      "Loading image:  2024-11-01 19:37:09.887528+00:00\n",
      "During prediction:  2024-11-01 19:37:09.914378+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:12.587597+00:00\n",
      "During prediction:  2024-11-01 19:37:12.618140+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:15.379205+00:00\n",
      "During prediction:  2024-11-01 19:37:15.405557+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:18.263670+00:00\n",
      "During prediction:  2024-11-01 19:37:18.300465+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:21.206150+00:00\n",
      "During prediction:  2024-11-01 19:37:21.242186+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:24.025024+00:00\n",
      "During prediction:  2024-11-01 19:37:24.050219+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 11\n",
      "Loading image:  2024-11-01 19:37:26.676943+00:00\n",
      "During prediction:  2024-11-01 19:37:26.702555+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:29.336461+00:00\n",
      "During prediction:  2024-11-01 19:37:29.369982+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:32.193156+00:00\n",
      "During prediction:  2024-11-01 19:37:32.217902+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:34.953079+00:00\n",
      "During prediction:  2024-11-01 19:37:34.977916+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:37.646567+00:00\n",
      "During prediction:  2024-11-01 19:37:37.681080+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:40.570762+00:00\n",
      "During prediction:  2024-11-01 19:37:40.607294+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 12\n",
      "Loading image:  2024-11-01 19:37:43.504754+00:00\n",
      "During prediction:  2024-11-01 19:37:43.538142+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:46.231235+00:00\n",
      "During prediction:  2024-11-01 19:37:46.267073+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:49.088528+00:00\n",
      "During prediction:  2024-11-01 19:37:49.121102+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:51.968849+00:00\n",
      "During prediction:  2024-11-01 19:37:52.006048+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:54.772899+00:00\n",
      "During prediction:  2024-11-01 19:37:54.808648+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:37:57.695710+00:00\n",
      "During prediction:  2024-11-01 19:37:57.731639+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 13\n",
      "Loading image:  2024-11-01 19:38:00.648080+00:00\n",
      "During prediction:  2024-11-01 19:38:00.681554+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:03.495807+00:00\n",
      "During prediction:  2024-11-01 19:38:03.531927+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:06.407264+00:00\n",
      "During prediction:  2024-11-01 19:38:06.440063+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:09.328744+00:00\n",
      "During prediction:  2024-11-01 19:38:09.365944+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:12.258174+00:00\n",
      "During prediction:  2024-11-01 19:38:12.293882+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:15.062759+00:00\n",
      "During prediction:  2024-11-01 19:38:15.092822+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 14\n",
      "Loading image:  2024-11-01 19:38:17.731416+00:00\n",
      "During prediction:  2024-11-01 19:38:17.764621+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:20.645861+00:00\n",
      "During prediction:  2024-11-01 19:38:20.687627+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:23.651118+00:00\n",
      "During prediction:  2024-11-01 19:38:23.683654+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:26.413127+00:00\n",
      "During prediction:  2024-11-01 19:38:26.438883+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:29.325043+00:00\n",
      "During prediction:  2024-11-01 19:38:29.360956+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:32.182651+00:00\n",
      "During prediction:  2024-11-01 19:38:32.218785+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 15\n",
      "Loading image:  2024-11-01 19:38:35.106709+00:00\n",
      "During prediction:  2024-11-01 19:38:35.132962+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:37.827715+00:00\n",
      "During prediction:  2024-11-01 19:38:37.863379+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:40.436920+00:00\n",
      "During prediction:  2024-11-01 19:38:40.469746+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:43.423319+00:00\n",
      "During prediction:  2024-11-01 19:38:43.452450+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:46.296237+00:00\n",
      "During prediction:  2024-11-01 19:38:46.321567+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:49.091584+00:00\n",
      "During prediction:  2024-11-01 19:38:49.127799+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 16\n",
      "Loading image:  2024-11-01 19:38:52.017104+00:00\n",
      "During prediction:  2024-11-01 19:38:52.050390+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:54.763759+00:00\n",
      "During prediction:  2024-11-01 19:38:54.809618+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:38:57.478859+00:00\n",
      "During prediction:  2024-11-01 19:38:57.505181+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:00.329311+00:00\n",
      "During prediction:  2024-11-01 19:39:00.366491+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:03.200396+00:00\n",
      "During prediction:  2024-11-01 19:39:03.224751+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:05.767330+00:00\n",
      "During prediction:  2024-11-01 19:39:05.803258+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 17\n",
      "Loading image:  2024-11-01 19:39:08.712378+00:00\n",
      "During prediction:  2024-11-01 19:39:08.738661+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:11.566074+00:00\n",
      "During prediction:  2024-11-01 19:39:11.596914+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:14.517688+00:00\n",
      "During prediction:  2024-11-01 19:39:14.539512+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:17.422567+00:00\n",
      "During prediction:  2024-11-01 19:39:17.459533+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:20.346547+00:00\n",
      "During prediction:  2024-11-01 19:39:20.370446+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:23.142616+00:00\n",
      "During prediction:  2024-11-01 19:39:23.178666+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 18\n",
      "Loading image:  2024-11-01 19:39:25.924957+00:00\n",
      "During prediction:  2024-11-01 19:39:25.958126+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:28.766113+00:00\n",
      "During prediction:  2024-11-01 19:39:28.808388+00:00\n",
      "Image: cat_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:31.480527+00:00\n",
      "During prediction:  2024-11-01 19:39:31.512930+00:00\n",
      "Image: cat_1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:34.213933+00:00\n",
      "During prediction:  2024-11-01 19:39:34.239854+00:00\n",
      "Image: cat_2.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:37.095007+00:00\n",
      "During prediction:  2024-11-01 19:39:37.130741+00:00\n",
      "Image: dog_0.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:40.014864+00:00\n",
      "During prediction:  2024-11-01 19:39:40.050794+00:00\n",
      "Image: dog_1.jpg\n",
      "\n",
      "Loop run count: 19\n",
      "Loading image:  2024-11-01 19:39:42.871911+00:00\n",
      "During prediction:  2024-11-01 19:39:42.905160+00:00\n",
      "Image: 1.jpg\n",
      "\n",
      "Loading image:  2024-11-01 19:39:45.728994+00:00\n",
      "During prediction:  2024-11-01 19:39:45.759076+00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-529d17f962aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     inference_time = classify_images(model, i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minference_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-bc7eb33aaf54>\u001b[0m in \u001b[0;36mclassify_images\u001b[0;34m(model, fps)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"During prediction: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimezone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Europe/London'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"During prediction: {datetime.datetime.now(pytz.timezone('Europe/London'))}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv3.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in range(1, 11):\n",
    "#     logging.info(\"\")\n",
    "#     inference_time = classify_images(model, i)\n",
    "\n",
    "inference_time = classify_images(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a0703-b565-4e1a-95e3-539af4ba25ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 11689512\n"
     ]
    }
   ],
   "source": [
    "# (1) FLOPS, the lower the better, \n",
    "# (2) number of parameters, the lower the better, \n",
    "# (3) fps, the higher the better, \n",
    "# (4) latency, the lower the better\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')\n",
    "logging.info(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e911f2d-d0d9-42cb-a896-b03a03af9956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PyTorch resnet18 pretrained on ImageNet\n",
      "Total FLOPs: 160093760\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained Mobilenetv3 model\n",
    "model = load_model(\"resnet18\")\n",
    "\n",
    "# Define input size (224x224x3) for Mobilenetv3\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = \"cuda\"\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.MaxPool2d):\n",
    "            # For max pooling layers\n",
    "            output_size = (input_size[0] - module.kernel_size) // module.stride + 1\n",
    "            flops += input_size[2] * output_size * output_size\n",
    "            input_size = (output_size, output_size, input_size[2])\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)\n",
    "logging.info(\"Total FLOPs:\", total_flops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc58d1-61e4-4ac7-8394-9e17eb45200d",
   "metadata": {},
   "source": [
    "Total FLOPs: 29234304\n",
    "Before loading model:  2024-10-18 17:57:17.025792+01:00\n",
    "\n",
    "0: 1.jpg\n",
    "\n",
    "Loading image:  2024-10-18 17:57:31.158511+01:00\n",
    "Image transformation:  2024-10-18 17:57:35.574077+01:00\n",
    "During prediction:  2024-10-18 17:57:39.639212+01:00\n",
    "Inference time: 2.9779 seconds\n",
    "Accuracy: 40.332%\n",
    "Predicted class:Italian greyhound\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 17, 948191)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 18, 950298)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 19, 952551)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 20, 942129)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 21, 943182)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 22, 943864)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 23, 957899)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 24, 966308)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 25, 954725)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 26, 951080)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 27, 965039)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 28, 964528)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 29, 970994)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 30, 957246)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 31, 966759)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 32, 969495)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 33, 959996)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 34, 972118)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 35, 974874)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 36, 975562)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 37, 976466)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 38, 966991)\n",
    "datetime.datetime(2024, 10, 18, 17, 57, 40, 053279)\n",
    "\n",
    "Average CPU Temperature: 31.13C\n",
    "Average GPU Temperature: 32.02C\n",
    "Average Power CPU: 868.96mW\n",
    "Average Power GPU: 868.96mW\n",
    "Average Power TOT: 2325.17mW\n",
    "Average RAM: 0.4688\n",
    "\n",
    "{'Avg_CPU_temp': 31.130434782608695, 'Avg_GPU_temp': 32.02173913043478, 'Avg_Power_CPU': 868.9565217391304, 'Avg_Power_GPU': 868.9565217391304, 'Avg_CPU_RAM': 0.46881048197927816}\n",
    "\n",
    "1: cat_0\n",
    "\n",
    "Loading image:  2024-10-18 17:59:21.789642+01:00\n",
    "Image transformation:  2024-10-18 17:59:24.607439+01:00\n",
    "During prediction:  2024-10-18 17:59:27.012594+01:00\n",
    "Inference time: 2.8112 seconds\n",
    "Accuracy: 14.485%\n",
    "Predicted class:water jug\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 21, 120204)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 22, 126424)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 23, 124276)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 24, 117592)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 25, 121873)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 26, 135385)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 27, 196186)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 28, 133128)\n",
    "datetime.datetime(2024, 10, 18, 17, 59, 29, 181014)\n",
    "\n",
    "Average CPU Temperature: 31.61C\n",
    "Average GPU Temperature: 32.50C\n",
    "Average Power CPU: 1231.00mW\n",
    "Average Power GPU: 1231.00mW\n",
    "Average Power TOT: 2643.22mW\n",
    "Average RAM: 0.4709\n",
    "{'Avg_CPU_temp': 31.61111111111111, 'Avg_GPU_temp': 32.5, 'Avg_Power_CPU': 1231.0, 'Avg_Power_GPU': 1231.0, 'Avg_CPU_RAM': 0.4708981101005223}\n",
    "\n",
    "2: cat_1\n",
    "Loading image:  2024-10-18 18:01:04.291168+01:00\n",
    "Image transformation:  2024-10-18 18:01:06.273660+01:00\n",
    "During prediction:  2024-10-18 18:01:09.836196+01:00\n",
    "Inference time: 2.8233 seconds\n",
    "Accuracy: 53.589%\n",
    "Predicted class:tabby, tabby cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 04, 259825)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 05, 279781)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 06, 262401)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 07, 274778)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 08, 276707)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 09, 277619)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 10, 316841)\n",
    "datetime.datetime(2024, 10, 18, 18, 01, 11, 342538)\n",
    "\n",
    "Average CPU Temperature: 31.69C\n",
    "Average GPU Temperature: 32.69C\n",
    "Average Power CPU: 1076.88mW\n",
    "Average Power GPU: 1076.88mW\n",
    "Average Power TOT: 2453.38mW\n",
    "Average RAM: 0.4712\n",
    "{'Avg_CPU_temp': 31.6875, 'Avg_GPU_temp': 32.6875, 'Avg_Power_CPU': 1076.875, 'Avg_Power_GPU': 1076.875, 'Avg_CPU_RAM': 0.47117206669228723}\n",
    "\n",
    "3: dog_0\n",
    "\n",
    "Loading image:  2024-10-18 18:03:41.256764+01:00\n",
    "Image transformation:  2024-10-18 18:03:43.954394+01:00\n",
    "During prediction:  2024-10-18 18:03:50.639748+01:00\n",
    "Inference time: 2.9095 seconds\n",
    "Accuracy: 69.595%\n",
    "Predicted class:malamute, malemute, Alaskan malamute\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 41, 482930)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 42, 480816)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 43, 488559)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 44, 482902)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 45, 488933)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 46, 492824)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 47, 505770)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 48, 501570)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 49, 491754)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 50, 501876)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 51, 510798)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 52, 532689)\n",
    "datetime.datetime(2024, 10, 18, 18, 03, 53, 498738)\n",
    "\n",
    "Average CPU Temperature: 31.58C\n",
    "Average GPU Temperature: 32.50C\n",
    "Average Power CPU: 1027.62mW\n",
    "Average Power GPU: 1027.62mW\n",
    "Average Power TOT: 2414.23mW\n",
    "Average RAM: 0.4707\n",
    "{'Avg_CPU_temp': 31.576923076923077, 'Avg_GPU_temp': 32.5, 'Avg_Power_CPU': 1027.6153846153845, 'Avg_Power_GPU': 1027.6153846153845, 'Avg_CPU_RAM': 0.4706899283154936}\n",
    "\n",
    "4: cat_2\n",
    "\n",
    "Loading image:  2024-10-18 18:05:06.948375+01:00\n",
    "Image transformation:  2024-10-18 18:05:09.383007+01:00\n",
    "During prediction:  2024-10-18 18:05:12.125914+01:00\n",
    "Inference time: 2.8526 seconds\n",
    "Accuracy: 99.132%\n",
    "Predicted class:Persian cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 06, 602950)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 07, 604978)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 08, 603793)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 09, 602987)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 10, 610692)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 11, 607423)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 12, 657260)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 13, 695027)\n",
    "datetime.datetime(2024, 10, 18, 18, 05, 14, 633435)\n",
    "\n",
    "Average CPU Temperature: 32.06C\n",
    "Average GPU Temperature: 32.72C\n",
    "Average Power CPU: 1279.44mW\n",
    "Average Power GPU: 1279.44mW\n",
    "Average Power TOT: 2683.11mW\n",
    "Average RAM: 0.4706\n",
    "{'Avg_CPU_temp': 32.05555555555556, 'Avg_GPU_temp': 32.72222222222222, 'Avg_Power_CPU': 1279.4444444444443, 'Avg_Power_GPU': 1279.4444444444443, 'Avg_CPU_RAM': 0.4706216489348307}\n",
    "\n",
    "5: dog_1\n",
    "\n",
    "Loading image:  2024-10-18 18:08:15.296827+01:00\n",
    "Image transformation:  2024-10-18 18:08:18.284938+01:00\n",
    "During prediction:  2024-10-18 18:08:22.015930+01:00\n",
    "Inference time: 2.6493 seconds\n",
    "Accuracy: 81.686%\n",
    "Predicted class:Newfoundland, Newfoundland dog\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 15, 866883)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 16, 864828)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 17, 858168)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 18, 875126)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 19, 869052)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 20, 874626)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 21, 874836)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 22, 882504)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 23, 974059)\n",
    "datetime.datetime(2024, 10, 18, 18, 08, 24, 877386)\n",
    "\n",
    "Average CPU Temperature: 31.80C\n",
    "Average GPU Temperature: 32.60C\n",
    "Average Power CPU: 1156.60mW\n",
    "Average Power GPU: 1156.60mW\n",
    "Average Power TOT: 2546.70mW\n",
    "Average RAM: 0.4706\n",
    "\n",
    "{'Avg_CPU_temp': 31.8, 'Avg_GPU_temp': 32.6, 'Avg_Power_CPU': 1156.6, 'Avg_Power_GPU': 1156.6, 'Avg_CPU_RAM': 0.4705887801657453}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96befa05-1645-4aca-b578-043cf231ce11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f30b7c-eec8-4f6b-bb35-64c5534650a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
