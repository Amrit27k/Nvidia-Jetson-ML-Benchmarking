{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4cb810-867b-4bbb-9875-eb41a67d3552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before loading model:  2024-10-18 17:02:37.795498+01:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import datetime\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "from PIL import Image\n",
    "import time\n",
    "import pytz\n",
    "# from jtop import jtop\n",
    "# jetson = jtop()\n",
    "# jetson.start()\n",
    "# print(\"Before loading model: \",jetson.stats)\n",
    "def read_classes():\n",
    "    \"\"\"\n",
    "    Load the ImageNet class names.\n",
    "    \"\"\"\n",
    "    with open(\"imagenet-classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip() for s in f.readlines()]\n",
    "    return categories\n",
    "\n",
    "print(\"Before loading model: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "# Load the pre-trained ResNet model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "# print(model)\n",
    "categories = read_classes()\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda43d6b-0fde-4cfb-80d3-ece62fcb2271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image:  2024-10-18 17:03:11.864517+01:00\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess an example image\n",
    "print(\"Loading image: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "image_path = 'cat_3.jpg'\n",
    "input_image = Image.open(image_path).convert('RGB')\n",
    "# print(\"Image transformation: \",jetson.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9671f4-fe24-4363-912e-e18dcf383c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image transformation:  2024-10-18 17:03:14.790826+01:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Image transformation: \",datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "# Define the image transformation pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to the input image\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e25fabc-3eae-4e50-965c-3cdc4b881ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During prediction:  2024-10-18 17:03:18.055401+01:00\n",
      "tensor([287])\n",
      "Predicted class: Dogs\n",
      "Inference time: 0.2995 seconds\n",
      "Accuracy: 99.623%\n",
      "class:lynx, catamount\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    print(\"During prediction: \", datetime.datetime.now(pytz.timezone('Europe/London')))\n",
    "    # print(\"During prediction: \",jtop().stats)\n",
    "    output = model(input_batch)\n",
    "    end_time = time.time()\n",
    "# get the softmax probabilities\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "# check the top 5 categories that are predicted\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 1)\n",
    "# Get the predicted class index\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "print(predicted_idx)\n",
    "predicted_class = \"Cats\" if predicted_idx.item() == 0 else \"Dogs\"\n",
    "\n",
    "# Print the predicted class label and inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n",
    "print(f\"Accuracy: {top5_prob[0].item()*100:.3f}%\")\n",
    "print(f\"class:{categories[top5_catid[0]]}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22c7ae83-5200-43b6-91c6-c69d6cfa36fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 11689512\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "934ed354-2eae-493b-ad9a-17a12ad9e89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 160093760\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained Mobilenetv3 model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Define input size (224x224x3) for Mobilenetv3\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.MaxPool2d):\n",
    "            # For max pooling layers\n",
    "            output_size = (input_size[0] - module.kernel_size) // module.stride + 1\n",
    "            flops += input_size[2] * output_size * output_size\n",
    "            input_size = (output_size, output_size, input_size[2])\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113153d1-d4fc-481f-b6fe-6fa9ad788cd4",
   "metadata": {},
   "source": [
    "Total FLOPs: 160093760\n",
    "\n",
    "0: 1.jpg\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 15, 33, 54, 868198)\n",
    "datetime.datetime(2024, 10, 18, 15, 33, 55, 868411)\n",
    "datetime.datetime(2024, 10, 18, 15, 33, 56, 870046)\n",
    "datetime.datetime(2024, 10, 18, 15, 33, 57, 870117)\n",
    "datetime.datetime(2024, 10, 18, 15, 33, 58, 869754)\n",
    "datetime.datetime(2024, 10, 18, 15, 33, 59, 873258)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 00, 873588)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 01, 871336)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 02, 889960)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 03, 887258)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 04, 887650)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 05, 882106)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 06, 893992)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 07, 884556)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 08, 903638)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 09, 928023)\n",
    "datetime.datetime(2024, 10, 18, 15, 34, 10, 909856)\n",
    "Average CPU Temperature: 28.47°C\n",
    "Average GPU Temperature: 29.74°C\n",
    "Average Power CPU: 818.88mW\n",
    "Average Power GPU: 818.88mW\n",
    "Average Power TOT: 2348.94mW\n",
    "Average RAM: 0.2104\n",
    "\n",
    "{'Avg_CPU_temp': 28.470588235294116, 'Avg_GPU_temp': 29.735294117647058, 'Avg_Power_CPU': 818.8823529411765, 'Avg_Power_GPU': 818.8823529411765, 'Avg_CPU_RAM': 0.2104423488140637}\n",
    "\n",
    "1: cat_0\n",
    "Loading image:  2024-10-18 16:46:20.909065+01:00\n",
    "Image transformation:  2024-10-18 16:46:22.104554+01:00\n",
    "During prediction:  2024-10-18 16:46:24.228559+01:00\n",
    "tensor([281])\n",
    "Predicted class: Dogs\n",
    "Inference time: 0.3439 seconds\n",
    "Accuracy: 18.534%\n",
    "class:tabby, tabby cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 00, 130376)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 01, 128240)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 02, 131405)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 03, 121917)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 04, 148955)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 05, 122257)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 06, 135844)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 07, 136782)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 08, 134811)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 09, 128557)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 10, 141018)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 11, 146300)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 12, 139647)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 13, 132430)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 14, 143442)\n",
    "\n",
    "Average CPU Temperature: 30.40°C\n",
    "Average GPU Temperature: 31.70°C\n",
    "Average Power CPU: 652.20mW\n",
    "Average Power GPU: 652.20mW\n",
    "Average Power TOT: 2098.60mW\n",
    "Average RAM: 0.4730\n",
    "\n",
    "{'Avg_CPU_temp': 30.4, 'Avg_GPU_temp': 31.7, 'Avg_Power_CPU': 652.2, 'Avg_Power_GPU': 652.2, 'Avg_CPU_RAM': 0.47296065273302396}\n",
    "\n",
    "2: cat_1\n",
    "Loading image:  2024-10-18 16:48:01.532727+01:00\n",
    "Image transformation:  2024-10-18 16:48:04.110424+01:00\n",
    "During prediction:  2024-10-18 16:48:12.566883+01:00\n",
    "tensor([281])\n",
    "Predicted class: Dogs\n",
    "Inference time: 0.2974 seconds\n",
    "Accuracy: 64.716%\n",
    "class:tabby, tabby cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 00, 130376)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 01, 128240)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 02, 131405)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 03, 121917)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 04, 148955)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 05, 122257)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 06, 135844)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 07, 136782)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 08, 134811)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 09, 128557)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 10, 141018)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 11, 146300)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 12, 139647)\n",
    "datetime.datetime(2024, 10, 18, 16, 48, 13, 132430)\n",
    "\n",
    "Average CPU Temperature: 30.61°C\n",
    "Average GPU Temperature: 31.89°C\n",
    "Average Power CPU: 674.57mW\n",
    "Average Power GPU: 674.57mW\n",
    "Average Power TOT: 2074.79mW\n",
    "Average RAM: 0.4728\n",
    "\n",
    "{'Avg_CPU_temp': 30.607142857142858, 'Avg_GPU_temp': 31.892857142857142, 'Avg_Power_CPU': 674.5714285714286, 'Avg_Power_GPU': 674.5714285714286, 'Avg_CPU_RAM': 0.47276098129558386}\n",
    "\n",
    "3: dog_0 \n",
    "Loading image:  2024-10-18 16:54:27.377465+01:00\n",
    "Image transformation:  2024-10-18 16:54:31.292117+01:00\n",
    "During prediction:  2024-10-18 16:54:37.215338+01:00\n",
    "tensor([249])\n",
    "Predicted class: Dogs\n",
    "Inference time: 0.3032 seconds\n",
    "Accuracy: 89.873%\n",
    "class:malamute, malemute, Alaskan malamute\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 27, 672386)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 28, 669776)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 29, 676345)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 30, 666303)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 31, 674525)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 32, 679884)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 33, 678402)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 34, 671880)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 35, 685031)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 36, 702716)\n",
    "datetime.datetime(2024, 10, 18, 16, 54, 37, 680425)\n",
    "\n",
    "Average CPU Temperature: 30.68°C\n",
    "Average GPU Temperature: 31.55°C\n",
    "Average Power CPU: 683.82mW\n",
    "Average Power GPU: 683.82mW\n",
    "Average Power TOT: 2043.55mW\n",
    "Average RAM: 0.4729\n",
    "\n",
    "{'Avg_CPU_temp': 30.681818181818183, 'Avg_GPU_temp': 31.545454545454547, 'Avg_Power_CPU': 683.8181818181819, 'Avg_Power_GPU': 683.8181818181819, 'Avg_CPU_RAM': 0.4729157540462119}\n",
    "\n",
    "4: cat_2 \n",
    "Before loading model:  2024-10-18 16:33:03.567822+01:00\n",
    "Image transformation:  2024-10-18 16:40:36.751187+01:00\n",
    "During prediction:  2024-10-18 16:40:39.892731+01:00\n",
    "tensor([283])\n",
    "Predicted class: Dogs\n",
    "Inference time: 0.3723 seconds\n",
    "Accuracy: 99.256%\n",
    "class:Persian cat\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 28, 481964)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 29, 488857)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 30, 487460)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 31, 489836)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 32, 486765)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 33, 494905)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 34, 495803)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 35, 499637)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 36, 502526)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 37, 495552)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 38, 498921)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 39, 501707)\n",
    "datetime.datetime(2024, 10, 18, 16, 40, 40, 493395)\n",
    "\n",
    "Average CPU Temperature: 30.58°C\n",
    "Average GPU Temperature: 31.62°C\n",
    "Average Power CPU: 716.62mW\n",
    "Average Power GPU: 716.62mW\n",
    "Average Power TOT: 2114.38mW\n",
    "Average RAM: 0.4728\n",
    "\n",
    "{'Avg_CPU_temp': 30.576923076923077, 'Avg_GPU_temp': 31.615384615384617, 'Avg_Power_CPU': 716.6153846153846, 'Avg_Power_GPU': 716.6153846153846, 'Avg_CPU_RAM': 0.47278330994888773}\n",
    "\n",
    "5: dog_1\n",
    "Loading image:  2024-10-18 16:56:22.115990+01:00\n",
    "Image transformation:  2024-10-18 16:56:26.635307+01:00\n",
    "During prediction:  2024-10-18 16:56:30.512122+01:00\n",
    "tensor([256])\n",
    "Predicted class: Dogs\n",
    "Inference time: 0.4154 seconds\n",
    "Accuracy: 63.549%\n",
    "class:Newfoundland, Newfoundland dog\n",
    "\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 22, 827212)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 23, 837316)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 24, 827328)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 25, 847038)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 26, 835788)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 27, 840432)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 28, 831363)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 29, 841117)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 30, 896692)\n",
    "datetime.datetime(2024, 10, 18, 16, 56, 31, 842305)\n",
    "Average CPU Temperature: 30.65°C\n",
    "Average GPU Temperature: 31.65°C\n",
    "Average Power CPU: 758.60mW\n",
    "Average Power GPU: 758.60mW\n",
    "Average Power TOT: 2159.50mW\n",
    "Average RAM: 0.4729\n",
    "\n",
    "{'Avg_CPU_temp': 30.65, 'Avg_GPU_temp': 31.65, 'Avg_Power_CPU': 758.6, 'Avg_Power_GPU': 758.6, 'Avg_CPU_RAM': 0.4729410431509347}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0b878-1343-4d15-9316-cc502e4e0c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
